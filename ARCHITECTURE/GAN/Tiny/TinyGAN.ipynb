{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Front Matter\n",
    "I want the Notebook to be as informative as possible, but model creating and training process follows some standard procedure that I do not want to repeat. Therefore, if you can, spend time reading the `PROLOGUE/Routine.ipynb` Notebook first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network - Tiny (TinyGAN)\n",
    "(Read where GAN came from [here](https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/).)\n",
    "\n",
    "Up to 2014, neural networks have proved their usefulness in computer vision, especially in the task of classification. However, there came a thorny problem: how to make neural networks that can *generate pictures*? Answers at such time was often not good: pictures of a man (or a woman, or a dog, for that matter) from the models were blurry or missing parts, such as an ear. One possible answer, from some friends of Ian Goodfellow (whom you may know through his [book](https://www.deeplearningbook.org/)) working on the project, involved intense number-crunching to help the model learn the statiscal elements that make up a picture (I have absolutely no idea what did the above sentence mean, you may as well assume it was written by ChatGPT and I copy-pasted it). That answer was clearly not good. Goodfellow, after some beer, came up with a much interesting idea: you can pitted two neural networks against each other for the task. How so? Consider a representative of the thing you want to generate, say, a picture of a cat, as a valuable piece of art (we are talking about cats, okay?). One neural network will be called *generator* with the task of generating *fake facsimiles* of this piece of art, while the other will be a *discriminator*, a detective with the task of discriminating between the real ones and the fake, generated ones. The goal of the first network is to generate images such that the discriminator's accuracy drops to 50% a.k.a it no longer knows which is which and is forced to guess randomly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the high-level understanding of GANs. Now let's go into details about each element, the discriminator and the generator, for our simple task of generating hand-written digits from the beloved [KMNIST](https://github.com/rois-codh/kmnist) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
