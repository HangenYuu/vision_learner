<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>routine</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="Routine_files/libs/clipboard/clipboard.min.js"></script>
<script src="Routine_files/libs/quarto-html/quarto.js"></script>
<script src="Routine_files/libs/quarto-html/popper.min.js"></script>
<script src="Routine_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Routine_files/libs/quarto-html/anchor.min.js"></script>
<link href="Routine_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Routine_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Routine_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Routine_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Routine_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="pytorch-routine" class="level1">
<h1>PyTorch routine</h1>
<p>For a total beginener to PyTorch, visit this <a href="https://www.learnpytorch.io/">website</a></p>
<section id="setting-up-on-colab" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-on-colab">0. Setting up on Colab</h2>
<p>Without a GPU, I always need to rely on Google Colab to train my model. A Colab instance is always come prepared with torch, but in case it does not, you need to set up with <code>pip</code>. I often install other modules to help with the post-training process. You need to pay Google for a CLI, but you could also make do with the code cell!</p>
<div class="cell" data-outputid="ee4fb18e-1cb4-4a64-d83c-58c14219761f">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install torch torchmetrics mlxtend</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)
Collecting torchmetrics
  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)
     |████████████████████████████████| 512 kB 4.5 MB/s 
Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (21.3)
Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.21.6)
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)
Requirement already satisfied: pandas&gt;=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)
Requirement already satisfied: scikit-learn&gt;=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)
Requirement already satisfied: matplotlib&gt;=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)
Requirement already satisfied: scipy&gt;=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=1.5.1-&gt;mlxtend) (3.0.9)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=1.5.1-&gt;mlxtend) (2.8.2)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=1.5.1-&gt;mlxtend) (0.11.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=1.5.1-&gt;mlxtend) (1.4.4)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas&gt;=0.17.1-&gt;mlxtend) (2022.6)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib&gt;=1.5.1-&gt;mlxtend) (1.15.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn&gt;=0.18-&gt;mlxtend) (1.2.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn&gt;=0.18-&gt;mlxtend) (3.1.0)
Installing collected packages: torchmetrics
Successfully installed torchmetrics-0.11.0</code></pre>
</div>
</div>
<div class="cell" data-outputid="98973992-4451-4f53-dece-f68684c7fc4c">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">--</span>upgrade mlxtend</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)
Collecting mlxtend
  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)
     |████████████████████████████████| 1.3 MB 4.9 MB/s 
Requirement already satisfied: scikit-learn&gt;=1.0.2 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)
Requirement already satisfied: matplotlib&gt;=3.0.0 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)
Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)
Requirement already satisfied: scipy&gt;=1.2.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)
Requirement already satisfied: numpy&gt;=1.16.2 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)
Requirement already satisfied: joblib&gt;=0.13.2 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.2.0)
Requirement already satisfied: pandas&gt;=0.24.2 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (3.0.9)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (1.4.4)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (0.11.0)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib&gt;=3.0.0-&gt;mlxtend) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas&gt;=0.24.2-&gt;mlxtend) (2022.6)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib&gt;=3.0.0-&gt;mlxtend) (1.15.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn&gt;=1.0.2-&gt;mlxtend) (3.1.0)
Installing collected packages: mlxtend
  Attempting uninstall: mlxtend
    Found existing installation: mlxtend 0.14.0
    Uninstalling mlxtend-0.14.0:
      Successfully uninstalled mlxtend-0.14.0
Successfully installed mlxtend-0.21.0</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Any other of your choice!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="import-modules" class="level2">
<h2 class="anchored" data-anchor-id="import-modules">1. Import modules</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generic torch process</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Specifically for computer vision</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor <span class="co">#Among others</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co"># For post-training process</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchmetrics <span class="im">import</span> ConfusionMatrix, Accuracy <span class="co">#Among others</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.plotting <span class="im">import</span> plot_confusion_matrix <span class="co">#Among others</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Import tqdm for progress bar</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Other module(s)</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="a-piece-of-device-agnostic-code" class="level3">
<h3 class="anchored" data-anchor-id="a-piece-of-device-agnostic-code">A piece of device-agnostic code</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="loading-data" class="level2">
<h2 class="anchored" data-anchor-id="loading-data">2. Loading data</h2>
<p>You load dataset in with <code>datasets</code>, and get them ready for the model with <code>DataLoader</code>, applying all the transformation you want or need.</p>
<p>The example is for the classic dataset - <del>MNIST</del> Kuzushiji-MNIST!</p>
<div class="cell" data-outputid="ff244a1a-e094-42c1-8432-7841342104bd">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> datasets.KMNIST(root<span class="op">=</span><span class="st">'DATA'</span>,</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                                   transform<span class="op">=</span>ToTensor(),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                   download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> datasets.KMNIST(root<span class="op">=</span><span class="st">'DATA'</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                                  transform<span class="op">=</span>ToTensor(),</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                                  download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>                                  train<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz
Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz to DATA/KMNIST/raw/train-images-idx3-ubyte.gz</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"68675b9ca5c44ae5a7dfb68ec54bb18d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Extracting DATA/KMNIST/raw/train-images-idx3-ubyte.gz to DATA/KMNIST/raw

Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz
Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz to DATA/KMNIST/raw/train-labels-idx1-ubyte.gz</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"feed1c9d09a04cdcae4250bd1fd275bf","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Extracting DATA/KMNIST/raw/train-labels-idx1-ubyte.gz to DATA/KMNIST/raw

Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz
Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz to DATA/KMNIST/raw/t10k-images-idx3-ubyte.gz</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"782bdb0723d04ed79e81a97fa0f0d04f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Extracting DATA/KMNIST/raw/t10k-images-idx3-ubyte.gz to DATA/KMNIST/raw

Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz
Downloading http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz to DATA/KMNIST/raw/t10k-labels-idx1-ubyte.gz</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4b03e67800bb4c56bc6a3cba16333504","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Extracting DATA/KMNIST/raw/t10k-labels-idx1-ubyte.gz to DATA/KMNIST/raw
</code></pre>
</div>
</div>
<div class="cell" data-outputid="3617c284-91c1-4052-ace1-20875c6ba8a2">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Exploring training example</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>image, label <span class="op">=</span> train_data[<span class="dv">0</span>]</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>image, label</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.4627, 1.0000, 1.0000, 0.4863, 0.0039,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.1412, 0.9333, 1.0000, 0.5725, 0.0078, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0471, 0.7961, 1.0000, 0.8627, 0.0549, 0.0000, 0.0000,
           0.0000, 0.0431, 0.5176, 0.3725, 0.7333, 0.3725, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.5843, 1.0000, 0.9843, 0.2588, 0.0000, 0.0000, 0.0000,
           0.0275, 0.6588, 0.5333, 0.0392, 0.8745, 0.9608, 0.2627, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.2000, 0.9686, 1.0000, 0.6118, 0.0039, 0.0000, 0.0000, 0.0000,
           0.5098, 0.7882, 0.0353, 0.0000, 0.6196, 1.0000, 0.6667, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431,
           0.8314, 1.0000, 0.8863, 0.0863, 0.0000, 0.0000, 0.0000, 0.3098,
           0.9412, 0.1490, 0.0000, 0.0000, 0.5608, 1.0000, 0.7725, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5804,
           1.0000, 1.0000, 0.4196, 0.0000, 0.0000, 0.0000, 0.1294, 0.9294,
           0.4745, 0.0000, 0.0000, 0.0000, 0.5647, 1.0000, 0.8706, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8039,
           1.0000, 0.6980, 0.0118, 0.0000, 0.0000, 0.0039, 0.7020, 0.8157,
           0.0196, 0.0000, 0.0000, 0.0000, 0.4941, 1.0000, 0.6510, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275, 0.9608,
           1.0000, 0.2980, 0.0000, 0.0000, 0.0000, 0.4863, 0.9961, 0.4235,
           0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 1.0000, 0.6118, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 1.0000,
           0.9373, 0.0471, 0.0000, 0.0000, 0.2431, 0.9804, 0.8824, 0.0314,
           0.0000, 0.0000, 0.0000, 0.0000, 0.3059, 1.0000, 0.7725, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1882, 1.0000,
           0.7529, 0.0000, 0.0000, 0.0627, 0.8118, 0.9882, 0.3294, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 1.0000, 0.6980, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2078, 1.0000,
           0.5804, 0.0000, 0.0000, 0.5216, 1.0000, 0.5804, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 1.0000, 0.6157, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3725, 1.0000,
           0.5608, 0.0000, 0.4118, 0.9882, 0.8627, 0.0667, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.3098, 1.0000, 0.3765, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5843, 1.0000,
           0.4745, 0.2275, 0.9647, 0.9961, 0.3098, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0275, 0.2078, 0.0039, 0.4000, 1.0000, 0.3922, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7922, 1.0000,
           0.8353, 0.9137, 1.0000, 0.7294, 0.0078, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0392, 0.1843, 0.5176, 1.0000, 0.3804, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.9647, 1.0000,
           1.0000, 1.0000, 0.9020, 0.0745, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.5647, 1.0000, 0.3725, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490, 1.0000, 1.0000,
           1.0000, 0.9529, 0.2784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.6157, 1.0000, 0.4118, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 1.0000, 1.0000,
           0.9961, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 1.0000, 0.4078, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.9882, 1.0000, 1.0000,
           0.9882, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0118, 0.9137, 1.0000, 0.4549, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.6314, 1.0000, 1.0000, 1.0000,
           0.9843, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0039, 0.8745, 1.0000, 0.6980, 0.0275,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.2196, 0.9882, 1.0000, 1.0000, 1.0000,
           0.9765, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.6235, 1.0000, 1.0000, 0.7098,
           0.0471, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.7059, 1.0000, 1.0000, 1.0000, 1.0000,
           0.9804, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.9608, 1.0000, 1.0000,
           0.6941, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0588, 0.9882, 1.0000, 1.0000, 1.0000, 1.0000,
           0.9294, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3804, 0.9922, 1.0000,
           0.9059, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0667, 0.9961, 0.9529, 0.8784, 1.0000, 1.0000,
           0.9373, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.9451, 1.0000,
           0.8353, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0196, 0.5882, 0.2745, 0.4039, 1.0000, 1.0000,
           0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.8706, 1.0000, 0.6824,
           0.0824, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2549, 1.0000, 0.9961,
           0.2431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.2314, 0.8902, 0.9647, 0.3647, 0.0078,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.9922, 0.7294,
           0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0941, 0.9412, 0.9412, 0.2980, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.5647, 0.1020,
           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.4784, 1.0000, 0.3529, 0.0000, 0.0000, 0.0000,
           0.0000, 0.0000, 0.0000, 0.0000]]]), 8)</code></pre>
</div>
</div>
<div class="cell" data-outputid="cd46f936-a196-4913-d105-df2f1f71d036">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>plt.imshow(image.squeeze())<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Routine_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-outputid="d3f3e5b1-8e12-429c-83ee-67fb387f1479">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> train_data.classes</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>class_names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>['o', 'ki', 'su', 'tsu', 'na', 'ha', 'ma', 'ya', 're', 'wo']</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating DataLoader object</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">2048</span> <span class="co"># Adjust the batch size based on GPU RAM</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>TrainLoader <span class="op">=</span> DataLoader(train_data, BATCH_SIZE, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>TestLoader <span class="op">=</span> DataLoader(test_data, BATCH_SIZE, shuffle<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="75ca42e0-4dbb-46e2-a95a-c695839ef652">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataloaders: </span><span class="sc">{</span>TrainLoader<span class="sc">,</span> TestLoader<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Length of train dataloader: </span><span class="sc">{</span><span class="bu">len</span>(TrainLoader)<span class="sc">}</span><span class="ss"> batches of </span><span class="sc">{</span>BATCH_SIZE<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Length of test dataloader: </span><span class="sc">{</span><span class="bu">len</span>(TestLoader)<span class="sc">}</span><span class="ss"> batches of </span><span class="sc">{</span>BATCH_SIZE<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataloaders: (&lt;torch.utils.data.dataloader.DataLoader object at 0x7f5c7d21a700&gt;, &lt;torch.utils.data.dataloader.DataLoader object at 0x7f5c7d21a9d0&gt;)
Length of train dataloader: 30 batches of 2048
Length of test dataloader: 5 batches of 2048</code></pre>
</div>
</div>
</section>
<section id="creating-the-model" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-model">3. Creating the model</h2>
<p>Here, we will do an unusual thing: creating a model from scratch. Why unusual? Normally, you would want to start with a pre-trained model with pre-trained weights and only adapt the parts (normally the “head” - the last layer) of the model to the task at hand. We do not exactly know how the model really “learn”, but there is a good chance that the early layers of the model pick up patterns that are also needed for our task. Take a look at the visualizations from this <a href="https://arxiv.org/abs/1311.2901">paper</a>: the early layers seem to pick up on edges, curves, and then circles, etc. which are kind of “universal patterns” in anything that you want to classify or generate. But well, I am getting ahead of myself, back to the model.</p>
<p>Now, since this is routine, I will create the most basic neural network model: fully-connected neural networks with 3 hidden layers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BasicModel(nn.Module):</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_shape: <span class="bu">int</span>, output_shape: <span class="bu">int</span>):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>            nn.Flatten(), <span class="co"># Flatten the image out</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span>input_shape, out_features<span class="op">=</span><span class="dv">256</span>),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">256</span>, out_features<span class="op">=</span><span class="dv">128</span>),</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">128</span>, out_features<span class="op">=</span><span class="dv">64</span>),</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">64</span>, out_features<span class="op">=</span><span class="dv">32</span>),</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>            nn.Linear(in_features<span class="op">=</span><span class="dv">32</span>, out_features<span class="op">=</span>output_shape),</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor):</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.classifier(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For the problem, we want to set <code>input_shape = 784</code>, as the dimensions for each image are 28*28, and <code>output_shape = len(class_names)</code>. This is a multiclass classification problem, so technically we will need to help a <code>softmax</code> last layer. However, it is better practice to output raw results (logits) and pass them into <code>softmax</code> later (the reason has to do with precision - go Google and Wikipedia, or probably just somewhere in the PyTorch documentation).</p>
<div class="cell" data-outputid="a3c67973-5127-455a-e787-629585058684">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the model. Set the seed for reproducibility</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">17</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> BasicModel(input_shape <span class="op">=</span> <span class="dv">784</span>,</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>                   output_shape <span class="op">=</span> <span class="bu">len</span>(class_names)).to(device)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">next</span>(model.parameters()).device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>device(type='cuda', index=0)</code></pre>
</div>
</div>
</section>
<section id="pick-the-loss-function-criterion-optimizer-and-metric" class="level2">
<h2 class="anchored" data-anchor-id="pick-the-loss-function-criterion-optimizer-and-metric">4. Pick the loss function (criterion), optimizer, and metric</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(params<span class="op">=</span>model.parameters(), </span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>                            lr<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> Accuracy(task<span class="op">=</span><span class="st">'multiclass'</span>, num_classes<span class="op">=</span><span class="bu">len</span>(class_names)).to(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">5. Training</h2>
<p>Training a model in PyTorch follows a pretty standard procedure. So much so that we can functionize the train and test step!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_step(model: torch.nn.Module,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>               data_loader: torch.utils.data.DataLoader,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>               criterion: torch.nn.Module,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>               optimizer: torch.optim.Optimizer,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>               metric: Accuracy,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>               device: torch.device <span class="op">=</span> device):</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>    train_loss, train_acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (X,y) <span class="kw">in</span> <span class="bu">enumerate</span>(data_loader):</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Forward pass</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        y_pred <span class="op">=</span> model(X)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Calculate loss &amp; accuracy</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> criterion(y_pred, y)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">+=</span> loss</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>        train_acc <span class="op">+=</span> metric(y_pred.argmax(dim<span class="op">=</span><span class="dv">1</span>), y)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 3. Empty out gradient</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 4. Backpropagation</span></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 5. Optimize 1 step</span></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">/=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>    train_acc <span class="op">/=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Train loss: </span><span class="sc">{</span>train_loss<span class="sc">:.5f}</span><span class="ss"> | Train accuracy: </span><span class="sc">{</span>train_acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_step(model: torch.nn.Module,</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>               data_loader: torch.utils.data.DataLoader,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>               criterion: torch.nn.Module,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>               metric: Accuracy,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>               device: torch.device <span class="op">=</span> device):</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    test_loss, acc <span class="op">=</span> <span class="dv">0</span>, <span class="dv">0</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.inference_mode():</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> (X,y) <span class="kw">in</span> data_loader:</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>            X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 1. Forward pass</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> model(X)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 2. Calculate loss &amp; accuracy</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> criterion(y_pred, y)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>            acc <span class="op">+=</span> metric(y_pred.argmax(dim<span class="op">=</span><span class="dv">1</span>), y)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">/=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>        acc <span class="op">/=</span> <span class="bu">len</span>(data_loader)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Test loss: </span><span class="sc">{</span>test_loss<span class="sc">:.5f}</span><span class="ss"> | Test accuracy: </span><span class="sc">{</span>acc<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="71b3d7a0-c8f7-420a-9ed6-6254d78d71b6">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if function is defined correctly</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ch">\n</span><span class="ss">---------"</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    train_step(data_loader<span class="op">=</span>TrainLoader, </span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model, </span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    test_step(data_loader<span class="op">=</span>TestLoader,</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a9e400e94cc740fbaed6cf8d49ea87f6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0
---------
Train loss: 8.50348 | Train accuracy: 0.15
Test loss: 2.21395 | Test accuracy: 0.17
Epoch: 1
---------
Train loss: 2.06660 | Train accuracy: 0.22
Test loss: 2.18012 | Test accuracy: 0.18</code></pre>
</div>
</div>
<div class="cell" data-outputid="927f77ee-6bae-4e62-98bd-37526a6a33ea">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Go big!</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ch">\n</span><span class="ss">---------"</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    train_step(data_loader<span class="op">=</span>TrainLoader, </span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model, </span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    test_step(data_loader<span class="op">=</span>TestLoader,</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0b9be8bda6f24896aa52b9734e169486","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0
---------
Train loss: 2.04674 | Train accuracy: 0.26
Test loss: 2.33638 | Test accuracy: 0.14
Epoch: 1
---------
Train loss: 2.09693 | Train accuracy: 0.25
Test loss: 2.43485 | Test accuracy: 0.20
Epoch: 2
---------
Train loss: 2.07174 | Train accuracy: 0.25
Test loss: 2.11362 | Test accuracy: 0.20
Epoch: 3
---------
Train loss: 1.99235 | Train accuracy: 0.26
Test loss: 2.08018 | Test accuracy: 0.23
Epoch: 4
---------
Train loss: 1.96704 | Train accuracy: 0.27
Test loss: 2.10831 | Test accuracy: 0.24
Epoch: 5
---------
Train loss: 2.78250 | Train accuracy: 0.26
Test loss: 13.34397 | Test accuracy: 0.17
Epoch: 6
---------
Train loss: 2.60214 | Train accuracy: 0.12
Test loss: 2.30258 | Test accuracy: 0.10
Epoch: 7
---------
Train loss: 2.30258 | Train accuracy: 0.10
Test loss: 2.30258 | Test accuracy: 0.10
Epoch: 8
---------
Train loss: 2.30258 | Train accuracy: 0.10
Test loss: 2.30258 | Test accuracy: 0.10
Epoch: 9
---------
Train loss: 2.30258 | Train accuracy: 0.10
Test loss: 2.30258 | Test accuracy: 0.10
Epoch: 10
---------
Train loss: 2.30258 | Train accuracy: 0.10
Test loss: 2.30258 | Test accuracy: 0.10
Epoch: 11
---------
Train loss: 2.30258 | Train accuracy: 0.10
Test loss: 2.30258 | Test accuracy: 0.10</code></pre>
</div>
</div>
<p>Uh oh, look like our model only peaked at roughly 20% accuracy and then regressed to random guesses! This is clearly overfitting! I will run it again back down to see if things get better with a smaller learning rate.</p>
<p>But before that, let’s use a little routine to empty out GPU RAM.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>gc.collect()</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> BasicModel(input_shape <span class="op">=</span> <span class="dv">784</span>,</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>                   output_shape <span class="op">=</span> <span class="bu">len</span>(class_names)).to(device)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(params<span class="op">=</span>model1.parameters(), </span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                            lr<span class="op">=</span><span class="fl">0.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="0bae641d-b674-495c-e08e-7e4fc5683d2f">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ch">\n</span><span class="ss">---------"</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    train_step(data_loader<span class="op">=</span>TrainLoader, </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model1, </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    test_step(data_loader<span class="op">=</span>TestLoader,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model1,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ed9e26a7c4e74844b11426ca4ca22312","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0
---------
Train loss: 1.71525 | Train accuracy: 0.40
Test loss: 1.64009 | Test accuracy: 0.42
Epoch: 1
---------
Train loss: 1.21122 | Train accuracy: 0.54
Test loss: 1.41001 | Test accuracy: 0.47
Epoch: 2
---------
Train loss: 1.08863 | Train accuracy: 0.57
Test loss: 1.31356 | Test accuracy: 0.50
Epoch: 3
---------
Train loss: 1.04061 | Train accuracy: 0.58
Test loss: 1.25006 | Test accuracy: 0.53
Epoch: 4
---------
Train loss: 1.01216 | Train accuracy: 0.58
Test loss: 1.23056 | Test accuracy: 0.52
Epoch: 5
---------
Train loss: 0.98900 | Train accuracy: 0.59
Test loss: 1.24966 | Test accuracy: 0.54
Epoch: 6
---------
Train loss: 0.97788 | Train accuracy: 0.59
Test loss: 1.29083 | Test accuracy: 0.54
Epoch: 7
---------
Train loss: 0.97544 | Train accuracy: 0.59
Test loss: 1.21861 | Test accuracy: 0.54
Epoch: 8
---------
Train loss: 0.96460 | Train accuracy: 0.59
Test loss: 1.25219 | Test accuracy: 0.54
Epoch: 9
---------
Train loss: 0.96443 | Train accuracy: 0.59
Test loss: 1.24812 | Test accuracy: 0.54
Epoch: 10
---------
Train loss: 0.95962 | Train accuracy: 0.59
Test loss: 1.25274 | Test accuracy: 0.54
Epoch: 11
---------
Train loss: 0.95726 | Train accuracy: 0.59
Test loss: 1.24894 | Test accuracy: 0.54</code></pre>
</div>
</div>
<p>Better results, but our model still hits a plateau at 59% training accuracy and 54% testing accuracy, and if you check the test loss, you will see it fluctuate around 1.25… something. Let’s try again with a different optimizer: <code>SGD</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>gc.collect()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.empty_cache()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> BasicModel(input_shape <span class="op">=</span> <span class="dv">784</span>,</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>                   output_shape <span class="op">=</span> <span class="bu">len</span>(class_names)).to(device)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(params<span class="op">=</span>model1.parameters(), </span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>                            lr<span class="op">=</span><span class="fl">0.01</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="f2aa6a27-44e1-4188-b126-9d3c37a2e02f">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(epochs)):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ch">\n</span><span class="ss">---------"</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    train_step(data_loader<span class="op">=</span>TrainLoader, </span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model2, </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>        optimizer<span class="op">=</span>optimizer,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    test_step(data_loader<span class="op">=</span>TestLoader,</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model2,</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>        criterion<span class="op">=</span>criterion,</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span>accuracy,</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span>device</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3ae1bf223f904d26929d68d0e5e2f7e8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch: 0
---------
Train loss: 2.30361 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 1
---------
Train loss: 2.30357 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 2
---------
Train loss: 2.30359 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 3
---------
Train loss: 2.30355 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 4
---------
Train loss: 2.30364 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 5
---------
Train loss: 2.30356 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 6
---------
Train loss: 2.30352 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 7
---------
Train loss: 2.30354 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 8
---------
Train loss: 2.30358 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 9
---------
Train loss: 2.30362 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 10
---------
Train loss: 2.30355 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10
Epoch: 11
---------
Train loss: 2.30360 | Train accuracy: 0.10
Test loss: 2.30377 | Test accuracy: 0.10</code></pre>
</div>
</div>
<p>Okay, disappointing result. But well, that is the spirit of hyperparameter tuning - experimenting to see what is the best set-up! But this is getting too long, so I will stop here. Now, <code>model1</code> seems to be the best choice so far, so let’s use it for inference.</p>
</section>
<section id="inference" class="level2">
<h2 class="anchored" data-anchor-id="inference">6. Inference</h2>
<div class="cell" data-outputid="8abedec9-dcd1-4e84-e61c-013238ff04a5">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Making predictions with the trained model</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>y_preds <span class="op">=</span> []</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>model1.<span class="bu">eval</span>()</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.inference_mode():</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> X, y <span class="kw">in</span> tqdm(TestLoader, desc<span class="op">=</span><span class="st">"Making predictions"</span>):</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Send data and targets to target device</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Do the forward pass</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    y_logit <span class="op">=</span> model1(X)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Turn predictions from logits -&gt; prediction probabilities -&gt; predictions labels</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> torch.softmax(y_logit, dim<span class="op">=</span><span class="dv">1</span>).argmax(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Put predictions on CPU for evaluation</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    y_preds.append(y_pred.cpu())</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Concatenate list of predictions into a tensor</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>y_pred_tensor <span class="op">=</span> torch.cat(y_preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5a9469426534d2193cbfdfe5cdbf065","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell" data-outputid="643476fa-4c94-42bd-c01b-cea97c1f44c5">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Setup confusion matrix instance and compare predictions to targets</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>confmat <span class="op">=</span> ConfusionMatrix(num_classes<span class="op">=</span><span class="bu">len</span>(class_names), task<span class="op">=</span><span class="st">'multiclass'</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>confmat_tensor <span class="op">=</span> confmat(preds<span class="op">=</span>y_pred_tensor,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                         target<span class="op">=</span>test_data.targets)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Plot the confusion matrix</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plot_confusion_matrix(</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    conf_mat<span class="op">=</span>confmat_tensor.numpy(), <span class="co"># matplotlib likes working with NumPy</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>    class_names <span class="op">=</span> class_names, <span class="co"># turn the row and column labels into class names</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>    figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Routine_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>I am not familiar with Kanji characters, but I think we should take a look at the ‘na’, ‘ha’, ‘ma’, ‘wo’ and ‘o’ characters, which are really alike in the pictures, and think of ways to help our model. However, that is outside the scope of this routine notebook, so I will stop here. Hope your, reader, is familiar with the PyTorch routine by now, and thank you for reading!</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>